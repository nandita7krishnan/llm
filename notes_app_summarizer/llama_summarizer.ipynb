{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Hotel Review Analyzer with Llama 3.2\n",
    "\n",
    "This notebook uses Llama 3.2 (1B or 3B) for analyzing hotel reviews with RAG.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. Accept the Llama license at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n",
    "2. Login with: `huggingface-cli login`\n",
    "3. Install required packages (see cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<2.0.0,>=0.3.78 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.44-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML<7.0.0,>=5.3.0 (from langchain-community)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-macosx_10_13_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-community)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.34-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.3.3-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.8.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.7.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.4.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.22.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=0.3.78->langchain-community)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain-community)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.11.3-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.41.1-cp311-cp311-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Downloading aiohttp-3.13.0-cp311-cp311-macosx_10_9_x86_64.whl (494 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.34-py3-none-any.whl (386 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp311-cp311-macosx_10_9_x86_64.whl (44 kB)\n",
      "Downloading pydantic-2.12.0-py3-none-any.whl (459 kB)\n",
      "Downloading pydantic_core-2.41.1-cp311-cp311-macosx_10_12_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-macosx_10_13_x86_64.whl (185 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl (204 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading yarl-1.22.0-cp311-cp311-macosx_10_9_x86_64.whl (94 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading frozenlist-1.8.0-cp311-cp311-macosx_10_9_x86_64.whl (50 kB)\n",
      "Downloading greenlet-3.2.4-cp311-cp311-macosx_11_0_universal2.whl (272 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.3.3-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.11.3-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (238 kB)\n",
      "Downloading propcache-0.4.1-cp311-cp311-macosx_10_9_x86_64.whl (45 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-macosx_10_9_x86_64.whl (795 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m795.3/795.3 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tenacity, sniffio, PyYAML, python-dotenv, pydantic-core, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, greenlet, frozenlist, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic-settings, httpx, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/44\u001b[0m [langchain-community]ommunity]ore]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.3 SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.0 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.3 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-community-0.3.31 langchain-core-0.3.79 langchain-text-splitters-0.3.11 langsmith-0.4.34 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.3.3 orjson-3.11.3 propcache-0.4.1 pydantic-2.12.0 pydantic-core-2.41.1 pydantic-settings-2.11.0 python-dotenv-1.1.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.2 urllib3-2.5.0 yarl-1.22.0 zstandard-0.25.0\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.2-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-macosx_10_10_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.9.18-cp311-cp311-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-macosx_10_12_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-macosx_10_12_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading regex-2025.9.18-cp311-cp311-macosx_10_9_x86_64.whl (288 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl (454 kB)\n",
      "Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp311-cp311-macosx_10_9_x86_64.whl (11 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-macosx_10_10_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-macosx_10_9_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.2-cp311-cp311-macosx_14_0_x86_64.whl (23.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, Pillow, networkx, MarkupSafe, joblib, hf-xet, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 Pillow-11.3.0 filelock-3.20.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.3 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 networkx-3.5 regex-2025.9.18 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 sentence-transformers-5.1.1 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.2.2 tqdm-4.67.1 transformers-4.57.0\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp311-cp311-macosx_13_0_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from faiss-cpu) (2.3.3)\n",
      "Requirement already satisfied: packaging in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.12.0-cp311-cp311-macosx_13_0_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Requirement already satisfied: transformers in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (4.57.0)\n",
      "Requirement already satisfied: filelock in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (0.35.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: sympy in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.10.1\n",
      "Requirement already satisfied: torch in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install langchain-community langchain\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install sentence-transformers\n",
    "!{sys.executable} -m pip install faiss-cpu\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install accelerate\n",
    "!{sys.executable} -m pip install torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...\n",
      "Total documents: 65399\n",
      "Sample: nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "\n",
    "# Load reviews\n",
    "print(\"Loading reviews...\")\n",
    "df = pd.read_csv(\"tripadvisor_hotel_reviews.csv\")\n",
    "\n",
    "# Split text into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "docs = splitter.create_documents(df[\"Review\"].tolist())\n",
    "\n",
    "print(f\"Total documents: {len(docs)}\")\n",
    "print(f\"Sample: {docs[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## Step 2: Create Embeddings and FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Creating embeddings (this may take a few minutes)...\n",
      "Note: This will be cached for future runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2044/2044 [17:53<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to cache...\n",
      "✓ Embeddings cached for future runs!\n",
      "Embeddings shape: (65399, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Extract text from documents\n",
    "docs_text = [doc.page_content for doc in docs]\n",
    "\n",
    "# Load embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Check if we have cached embeddings\n",
    "cache_file = 'embeddings_cache.pkl'\n",
    "if os.path.exists(cache_file):\n",
    "    print(\"Loading cached embeddings...\")\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    print(\"✓ Loaded cached embeddings!\")\n",
    "else:\n",
    "    # Create embeddings (this takes ~78 minutes, so we'll cache it)\n",
    "    print(\"Creating embeddings (this may take a few minutes)...\")\n",
    "    print(\"Note: This will be cached for future runs\")\n",
    "    embeddings = embedding_model.encode(\n",
    "        docs_text, \n",
    "        show_progress_bar=True,\n",
    "        device='cpu',\n",
    "        convert_to_tensor=True  # Get as tensor first\n",
    "    )\n",
    "    \n",
    "    # Manually convert tensor to numpy (workaround for numpy availability issue)\n",
    "    # Convert to list first, then to numpy array to avoid PyTorch-NumPy incompatibility\n",
    "    embeddings = np.array(embeddings.cpu().tolist(), dtype='float32')\n",
    "    \n",
    "    # Save to cache\n",
    "    print(\"Saving embeddings to cache...\")\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "    print(\"✓ Embeddings cached for future runs!\")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faiss_index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created with 65399 vectors of dimension 384\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Keep mapping from FAISS id → original text\n",
    "id_to_text = {i: doc.page_content for i, doc in enumerate(docs)}\n",
    "\n",
    "print(f\"Index created with {index.ntotal} vectors of dimension {dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## Step 3: Define Semantic Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "search_function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test search results:\n",
      "1. staff efficient friendly lacked warm touch.the room 5th floor small dark clean nicely furnished, vie...\n",
      "2. hotel staff friendly helpful, rooms small not comfortable clean, say hotel just okay price right,...\n",
      "3. friendly clean great location room clean great location helpful friendly staff.our room overlooking ...\n"
     ]
    }
   ],
   "source": [
    "def semantic_search(query, k=10):\n",
    "    \"\"\"Search for top-k most relevant reviews\"\"\"\n",
    "    # Encode query with tensor conversion workaround\n",
    "    query_tensor = embedding_model.encode([query], convert_to_tensor=True, device='cpu')\n",
    "    query_emb = np.array(query_tensor.cpu().tolist(), dtype='float32')\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    return [id_to_text[i] for i in indices[0]]\n",
    "\n",
    "# Test the search\n",
    "test_results = semantic_search(\"clean rooms and friendly staff\", k=3)\n",
    "print(\"Test search results:\")\n",
    "for i, result in enumerate(test_results, 1):\n",
    "    print(f\"{i}. {result[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## Step 4: Load Llama 3.2 Model\n",
    "\n",
    "**Note:** This will download ~1GB for the 1B model or ~3GB for the 3B model.\n",
    "\n",
    "**Options:**\n",
    "- `meta-llama/Llama-3.2-1B-Instruct` - Lightweight, fast (recommended for laptops)\n",
    "- `meta-llama/Llama-3.2-3B-Instruct` - Better quality, slower\n",
    "\n",
    "**Warning:** This may take several minutes and could crash if you don't have enough RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae22672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-stack\n",
      "  Downloading llama_stack-0.2.12-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (3.13.0)\n",
      "Collecting fastapi<1.0,>=0.115.0 (from llama-stack)\n",
      "  Downloading fastapi-0.118.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting fire (from llama-stack)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: httpx in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (0.35.3)\n",
      "Requirement already satisfied: jinja2>=3.1.6 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (3.1.6)\n",
      "Collecting jsonschema (from llama-stack)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting llama-stack-client>=0.2.12 (from llama-stack)\n",
      "  Downloading llama_stack_client-0.2.12-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting openai>=1.66 (from llama-stack)\n",
      "  Downloading openai-2.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: prompt-toolkit in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (3.0.52)\n",
      "Requirement already satisfied: python-dotenv in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (1.1.1)\n",
      "Collecting python-jose (from llama-stack)\n",
      "  Downloading python_jose-3.5.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (2.12.0)\n",
      "Requirement already satisfied: requests in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (2.32.5)\n",
      "Collecting rich (from llama-stack)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: setuptools in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (78.1.1)\n",
      "Collecting starlette (from llama-stack)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting termcolor (from llama-stack)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting tiktoken (from llama-stack)\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pillow in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (11.3.0)\n",
      "Requirement already satisfied: h11>=0.16.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack) (0.16.0)\n",
      "Collecting python-multipart>=0.0.20 (from llama-stack)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from fastapi<1.0,>=0.115.0->llama-stack) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pydantic>=2->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pydantic>=2->llama-stack) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pydantic>=2->llama-stack) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from starlette->llama-stack) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette->llama-stack) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette->llama-stack) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from jinja2>=3.1.6->llama-stack) (3.0.3)\n",
      "Collecting click (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pandas in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack-client>=0.2.12->llama-stack) (2.3.3)\n",
      "Collecting pyaml (from llama-stack-client>=0.2.12->llama-stack)\n",
      "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tqdm in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from llama-stack-client>=0.2.12->llama-stack) (4.67.1)\n",
      "Requirement already satisfied: certifi in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from httpx->llama-stack) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from httpx->llama-stack) (1.0.9)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.66->llama-stack)\n",
      "  Downloading jiter-0.11.0-cp311-cp311-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from aiohttp->llama-stack) (1.22.0)\n",
      "Requirement already satisfied: filelock in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub->llama-stack) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub->llama-stack) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub->llama-stack) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub->llama-stack) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from huggingface-hub->llama-stack) (1.1.10)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->llama-stack)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->llama-stack)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->llama-stack)\n",
      "  Downloading rpds_py-0.27.1-cp311-cp311-macosx_10_12_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client>=0.2.12->llama-stack) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from prompt-toolkit->llama-stack) (0.2.14)\n",
      "Collecting ecdsa!=0.15 (from python-jose->llama-stack)\n",
      "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Collecting rsa!=4.1.1,!=4.4,<5.0,>=4.0 (from python-jose->llama-stack)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.5.0 (from python-jose->llama-stack)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->llama-stack) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from requests->llama-stack) (2.5.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->llama-stack)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from rich->llama-stack) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->llama-stack)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/nanditakrishnan/llm/.conda/lib/python3.11/site-packages (from tiktoken->llama-stack) (2025.9.18)\n",
      "Downloading llama_stack-0.2.12-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.118.3-py3-none-any.whl (97 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading llama_stack_client-0.2.12-py3-none-any.whl (340 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading openai-2.3.0-py3-none-any.whl (999 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m999.8/999.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.11.0-cp311-cp311-macosx_10_12_x86_64.whl (309 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp311-cp311-macosx_10_12_x86_64.whl (371 kB)\n",
      "Downloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
      "Downloading python_jose-3.5.0-py2.py3-none-any.whl (34 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: termcolor, rpds-py, python-multipart, pyasn1, pyaml, mdurl, jiter, ecdsa, distro, click, tiktoken, starlette, rsa, referencing, markdown-it-py, fire, rich, python-jose, openai, jsonschema-specifications, fastapi, llama-stack-client, jsonschema, llama-stack\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [llama-stack]\u001b[0m [llama-stack]client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed click-8.3.0 distro-1.9.0 ecdsa-0.19.1 fastapi-0.118.3 fire-0.7.1 jiter-0.11.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 llama-stack-0.2.12 llama-stack-client-0.2.12 markdown-it-py-4.0.0 mdurl-0.1.2 openai-2.3.0 pyaml-25.7.0 pyasn1-0.6.1 python-jose-3.5.0 python-multipart-0.0.20 referencing-0.36.2 rich-14.2.0 rpds-py-0.27.1 rsa-4.9.1 starlette-0.48.0 termcolor-3.1.0 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install llama-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llama_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta-llama/Llama-3.2-1B-Instruct...\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n403 Client Error. (Request ID: Root=1-68e9b04f-3c5965076d97cbdf1107b113;6880c30e-2d14-435e-82bd-60d5a4935ff9)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1658\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1655\u001b[39m ):\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:424\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    421\u001b[39m     message = (\n\u001b[32m    422\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mGatedRepoError\u001b[39m: 403 Client Error. (Request ID: Root=1-68e9b04f-3c5965076d97cbdf1107b113;6880c30e-2d14-435e-82bd-60d5a4935ff9)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThis may take a few minutes...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load model with memory optimization\u001b[39;00m\n\u001b[32m     14\u001b[39m llama_model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     15\u001b[39m     model_id,\n\u001b[32m     16\u001b[39m     torch_dtype=torch.float16 \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m torch.float32,\n\u001b[32m     17\u001b[39m     device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     low_cpu_mem_usage=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1093\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m   1092\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1096\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1333\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1330\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1331\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1335\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/configuration_utils.py:662\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    660\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/configuration_utils.py:721\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    720\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm/.conda/lib/python3.11/site-packages/transformers/utils/hub.py:543\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    542\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    544\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    545\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[32m    548\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n403 Client Error. (Request ID: Root=1-68e9b04f-3c5965076d97cbdf1107b113;6880c30e-2d14-435e-82bd-60d5a4935ff9)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access."
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Use Ollama (much simpler - no authentication needed!)\n",
    "print(\"Connecting to Ollama...\")\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Test the connection\n",
    "print(\"Testing Ollama connection...\")\n",
    "test_response = llm.invoke(\"Say 'Hello, I'm ready!' in one sentence.\")\n",
    "print(f\"Test response: {test_response}\")\n",
    "\n",
    "print(\"✓ Ollama connected successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## Step 5: Define Summarization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llama_summarize",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_summarize(reviews_text, question):\n",
    "    \"\"\"Use Llama (via Ollama) to summarize reviews and answer questions\"\"\"\n",
    "    \n",
    "    # Simpler prompt for Ollama\n",
    "    prompt = f\"\"\"You are analyzing hotel reviews. Provide concise bullet-point summaries.\n",
    "\n",
    "Based on these hotel reviews:\n",
    "{reviews_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide key insights in bullet points only.\"\"\"\n",
    "    \n",
    "    # Generate response using Ollama\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rag_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(query, top_k=10, max_chars=1500):\n",
    "    \"\"\"\n",
    "    RAG pipeline:\n",
    "    1. Retrieve top-k relevant reviews\n",
    "    2. Truncate to fit context window\n",
    "    3. Generate summary with Llama\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant reviews\n",
    "    print(f\"🔍 Searching for: '{query}'...\")\n",
    "    top_reviews = semantic_search(query, k=top_k)\n",
    "    \n",
    "    # Step 2: Combine and truncate reviews\n",
    "    combined_reviews = \"\\n---\\n\".join(top_reviews)\n",
    "    if len(combined_reviews) > max_chars:\n",
    "        combined_reviews = combined_reviews[:max_chars] + \"...\"\n",
    "    \n",
    "    # Step 3: Generate summary\n",
    "    print(\"🤖 Generating summary...\")\n",
    "    summary = llama_summarize(combined_reviews, query)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## Step 6: Test with Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Positive reviews\n",
    "query = \"What do most positive reviews have in common?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "result = rag_query(query, top_k=10)\n",
    "print(f\"\\nAnswer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Negative reviews\n",
    "query = \"What do most negative reviews complain about?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "result = rag_query(query, top_k=10)\n",
    "print(f\"\\nAnswer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Hotel staff\n",
    "query = \"How is the hotel staff described?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "result = rag_query(query, top_k=10)\n",
    "print(f\"\\nAnswer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_cleanliness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4: Cleanliness\n",
    "query = \"What about cleanliness and room conditions?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "result = rag_query(query, top_k=10)\n",
    "print(f\"\\nAnswer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## Step 7: Ask Your Own Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_query",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask your own question\n",
    "my_question = \"Is the hotel good for families with kids?\"\n",
    "\n",
    "result = rag_query(my_question, top_k=10)\n",
    "print(f\"\\nAnswer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes and Tips\n",
    "\n",
    "### Model Options:\n",
    "- **Llama-3.2-1B-Instruct**: Lightweight (~1GB RAM), fast inference, good for laptops\n",
    "- **Llama-3.2-3B-Instruct**: Better quality (~3GB RAM), moderate speed\n",
    "\n",
    "### Authentication:\n",
    "To use Llama models, you need to:\n",
    "1. Accept the license at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n",
    "2. Login with: `huggingface-cli login` (or set `HF_TOKEN` environment variable)\n",
    "\n",
    "### Performance Tips:\n",
    "- **Reduce `top_k`** if generation is slow (try 5-7 instead of 10)\n",
    "- **Use `max_chars`** to limit context size (default: 1500)\n",
    "- **Adjust `max_new_tokens`** in the generator for shorter/longer responses\n",
    "- **Use GPU** if available by setting `torch_dtype=torch.float16`\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Kernel crashes**: Your system doesn't have enough RAM. Try the 1B model instead of 3B.\n",
    "- **Slow generation**: Reduce `top_k` to 5-7, or use fewer reviews.\n",
    "- **Repetitive output**: Increase `repetition_penalty` to 1.2-1.3.\n",
    "- **Authentication errors**: Make sure you've accepted the license and logged in.\n",
    "\n",
    "### Alternative: Use Ollama (Easier!)\n",
    "If you want to avoid the complexity of HuggingFace authentication:\n",
    "\n",
    "```python\n",
    "# 1. Install Ollama: https://ollama.ai\n",
    "# 2. Run in terminal: ollama pull llama3.2\n",
    "# 3. Use in code:\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "response = llm(\"Summarize these reviews: ...\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf978c13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958d39fc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
